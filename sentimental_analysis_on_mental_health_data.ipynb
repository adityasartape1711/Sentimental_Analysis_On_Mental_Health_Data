{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf8d3820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ff7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Combined Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db771361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          statement   status\n",
       "0           0                                         oh my gosh  Anxiety\n",
       "1           1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
       "2           2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
       "3           3  I've shifted my focus to something else but I'...  Anxiety\n",
       "4           4  I'm restless and restless, it's been a month n...  Anxiety"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c14621dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      0\n",
       "statement     362\n",
       "status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "430987e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     int64\n",
       "statement     object\n",
       "status        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c9f884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53043.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15312.339501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13260.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39781.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>53042.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0\n",
       "count  53043.000000\n",
       "mean   26521.000000\n",
       "std    15312.339501\n",
       "min        0.000000\n",
       "25%    13260.500000\n",
       "50%    26521.000000\n",
       "75%    39781.500000\n",
       "max    53042.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498d49c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null Values After Cleaning:\n",
      " Unnamed: 0    0\n",
      "statement     0\n",
      "status        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where 'statement' is null\n",
    "df.dropna(subset=['statement'], inplace=True)\n",
    "\n",
    "# Verify missing values have been handled\n",
    "print(\"\\nNull Values After Cleaning:\\n\", df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47df05a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Statements:\n",
      "                                            statement  \\\n",
      "0                                         oh my gosh   \n",
      "1  trouble sleeping, confused mind, restless hear...   \n",
      "2  All wrong, back off dear, forward doubt. Stay ...   \n",
      "3  I've shifted my focus to something else but I'...   \n",
      "4  I'm restless and restless, it's been a month n...   \n",
      "\n",
      "                                   cleaned_statement  \n",
      "0                                         oh my gosh  \n",
      "1  trouble sleeping confused mind restless heart ...  \n",
      "2  all wrong back off dear forward doubt stay in ...  \n",
      "3  i ve shifted my focus to something else but i ...  \n",
      "4  i m restless and restless it s been a month no...  \n"
     ]
    }
   ],
   "source": [
    "# Define a function to clean text\n",
    "def clean_text(text):\n",
    "    import re\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'statement' column\n",
    "df['cleaned_statement'] = df['statement'].apply(clean_text)\n",
    "\n",
    "# Display cleaned statements\n",
    "print(\"\\nCleaned Statements:\\n\", df[['statement', 'cleaned_statement']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9989eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01f130ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Scores:\n",
      "                                    cleaned_statement  sentiment_score\n",
      "0                                         oh my gosh           0.0000\n",
      "1  trouble sleeping confused mind restless heart ...          -0.3000\n",
      "2  all wrong back off dear forward doubt stay in ...          -0.2500\n",
      "3  i ve shifted my focus to something else but i ...           0.0000\n",
      "4  i m restless and restless it s been a month no...          -0.3125\n"
     ]
    }
   ],
   "source": [
    "# Define a function to calculate sentiment polarity\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Apply the function to calculate sentiment score\n",
    "df['sentiment_score'] = df['cleaned_statement'].apply(get_sentiment)\n",
    "\n",
    "# Display sentiment scores\n",
    "print(\"\\nSentiment Scores:\\n\", df[['cleaned_statement', 'sentiment_score']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "801ff073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classified Sentiments:\n",
      "                                    cleaned_statement sentiment  \\\n",
      "0                                         oh my gosh   Neutral   \n",
      "1  trouble sleeping confused mind restless heart ...  Negative   \n",
      "2  all wrong back off dear forward doubt stay in ...  Negative   \n",
      "3  i ve shifted my focus to something else but i ...   Neutral   \n",
      "4  i m restless and restless it s been a month no...  Negative   \n",
      "\n",
      "   sentiment_score  \n",
      "0           0.0000  \n",
      "1          -0.3000  \n",
      "2          -0.2500  \n",
      "3           0.0000  \n",
      "4          -0.3125  \n"
     ]
    }
   ],
   "source": [
    "# Define a function to classify sentiment\n",
    "def classify_sentiment(score):\n",
    "    if score > 0:\n",
    "        return 'Positive'\n",
    "    elif score < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply the function to classify sentiment\n",
    "df['sentiment'] = df['sentiment_score'].apply(classify_sentiment)\n",
    "\n",
    "# Display classified sentiments\n",
    "print(\"\\nClassified Sentiments:\\n\", df[['cleaned_statement', 'sentiment', 'sentiment_score']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5987d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "     ------------------------------------ 126.0/126.0 kB 494.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from vaderSentiment) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests->vaderSentiment) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests->vaderSentiment) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests->vaderSentiment) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests->vaderSentiment) (2.1.1)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8995ca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VADER Sentiment Analysis:\n",
      "                                    cleaned_statement  vader_compound  \\\n",
      "0                                         oh my gosh          0.0000   \n",
      "1  trouble sleeping confused mind restless heart ...         -0.2263   \n",
      "2  all wrong back off dear forward doubt stay in ...         -0.7351   \n",
      "3  i ve shifted my focus to something else but i ...         -0.4215   \n",
      "4  i m restless and restless it s been a month no...         -0.4939   \n",
      "\n",
      "   vader_positive  vader_neutral  vader_negative  \n",
      "0           0.000          1.000           0.000  \n",
      "1           0.243          0.347           0.410  \n",
      "2           0.121          0.421           0.458  \n",
      "3           0.000          0.811           0.189  \n",
      "4           0.000          0.769           0.231  \n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function for VADER sentiment analysis\n",
    "def vader_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores['compound'], scores['pos'], scores['neu'], scores['neg']\n",
    "\n",
    "# Apply VADER analysis\n",
    "df['vader_compound'], df['vader_positive'], df['vader_neutral'], df['vader_negative'] = zip(\n",
    "    *df['cleaned_statement'].apply(vader_sentiment)\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nVADER Sentiment Analysis:\\n\", df[['cleaned_statement', 'vader_compound', 'vader_positive', 'vader_neutral', 'vader_negative']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f190ff61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "     -------------------------------------- 10.0/10.0 MB 148.8 kB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0,>=0.23.2\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "     ------------------------------------ 447.6/447.6 kB 120.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (6.0)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp310-none-win_amd64.whl (285 kB)\n",
      "     ------------------------------------ 285.9/285.9 kB 114.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (1.23.5)\n",
      "Collecting tokenizers<0.21,>=0.20\n",
      "  Downloading tokenizers-0.20.3-cp310-none-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 101.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.6.1)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "     ------------------------------------ 179.6/179.6 kB 135.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers) (2.1.1)\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed fsspec-2024.10.0 huggingface-hub-0.26.3 safetensors-0.4.5 tokenizers-0.20.3 transformers-4.46.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c537a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.83      0.75      0.79       755\n",
      "             Bipolar       0.88      0.70      0.78       527\n",
      "          Depression       0.69      0.74      0.72      3016\n",
      "              Normal       0.86      0.95      0.90      3308\n",
      "Personality disorder       0.87      0.43      0.58       237\n",
      "              Stress       0.71      0.50      0.58       536\n",
      "            Suicidal       0.71      0.67      0.69      2158\n",
      "\n",
      "            accuracy                           0.77     10537\n",
      "           macro avg       0.79      0.68      0.72     10537\n",
      "        weighted avg       0.77      0.77      0.77     10537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Vectorize text data\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df['cleaned_statement']).toarray()\n",
    "\n",
    "# Prepare labels (Assume 'status' contains the sentiment labels)\n",
    "y = df['status']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c42bdbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lexicon Sentiment Analysis:\n",
      "                                    cleaned_statement  lexicon_sentiment\n",
      "0                                         oh my gosh                  0\n",
      "1  trouble sleeping confused mind restless heart ...                  0\n",
      "2  all wrong back off dear forward doubt stay in ...                  0\n",
      "3  i ve shifted my focus to something else but i ...                  0\n",
      "4  i m restless and restless it s been a month no...                  0\n",
      "\n",
      "Lexicon Sentiment Analysis:\n",
      "                                    cleaned_statement  lexicon_sentiment\n",
      "0                                         oh my gosh                  0\n",
      "1  trouble sleeping confused mind restless heart ...                  0\n",
      "2  all wrong back off dear forward doubt stay in ...                  0\n",
      "3  i ve shifted my focus to something else but i ...                  0\n",
      "4  i m restless and restless it s been a month no...                  0\n"
     ]
    }
   ],
   "source": [
    "# Define a custom lexicon\n",
    "custom_lexicon = {\n",
    "    'happy': 1, 'joy': 1, 'sad': -1, 'anxious': -1, 'relaxed': 1, 'depressed': -1\n",
    "}\n",
    "\n",
    "# Function to calculate sentiment score based on custom lexicon\n",
    "def lexicon_sentiment(text):\n",
    "    score = 0\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        score += custom_lexicon.get(word, 0)  # Default score is 0 for unknown words\n",
    "    return score\n",
    "\n",
    "# Apply lexicon-based sentiment analysis\n",
    "df['lexicon_sentiment'] = df['cleaned_statement'].apply(lexicon_sentiment)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nLexicon Sentiment Analysis:\\n\", df[['cleaned_statement', 'lexicon_sentiment']].head())\n",
    "# Define a custom lexicon\n",
    "custom_lexicon = {\n",
    "    'happy': 1, 'joy': 1, 'sad': -1, 'anxious': -1, 'relaxed': 1, 'depressed': -1\n",
    "}\n",
    "\n",
    "# Function to calculate sentiment score based on custom lexicon\n",
    "def lexicon_sentiment(text):\n",
    "    score = 0\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        score += custom_lexicon.get(word, 0)  # Default score is 0 for unknown words\n",
    "    return score\n",
    "\n",
    "# Apply lexicon-based sentiment analysis\n",
    "df['lexicon_sentiment'] = df['cleaned_statement'].apply(lexicon_sentiment)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nLexicon Sentiment Analysis:\\n\", df[['cleaned_statement', 'lexicon_sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e8c6ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rule-Based Sentiment Analysis:\n",
      "                                    cleaned_statement rule_based_sentiment\n",
      "0                                         oh my gosh              Neutral\n",
      "1  trouble sleeping confused mind restless heart ...              Neutral\n",
      "2  all wrong back off dear forward doubt stay in ...              Neutral\n",
      "3  i ve shifted my focus to something else but i ...              Neutral\n",
      "4  i m restless and restless it s been a month no...              Neutral\n"
     ]
    }
   ],
   "source": [
    "# Define rules\n",
    "def rule_based_sentiment(text):\n",
    "    if 'not good' in text or 'bad' in text:\n",
    "        return 'Negative'\n",
    "    elif 'great' in text or 'good' in text:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply rule-based sentiment analysis\n",
    "df['rule_based_sentiment'] = df['cleaned_statement'].apply(rule_based_sentiment)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nRule-Based Sentiment Analysis:\\n\", df[['cleaned_statement', 'rule_based_sentiment']].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfc15f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1186/1186 [==============================] - 694s 578ms/step - loss: 0.9132 - accuracy: 0.6371 - val_loss: 0.7691 - val_accuracy: 0.7013\n",
      "Epoch 2/5\n",
      "1186/1186 [==============================] - 689s 581ms/step - loss: 0.6619 - accuracy: 0.7452 - val_loss: 0.6991 - val_accuracy: 0.7359\n",
      "Epoch 3/5\n",
      "1186/1186 [==============================] - 638s 538ms/step - loss: 0.5466 - accuracy: 0.7936 - val_loss: 0.6660 - val_accuracy: 0.7471\n",
      "Epoch 4/5\n",
      "1186/1186 [==============================] - 641s 541ms/step - loss: 0.4672 - accuracy: 0.8225 - val_loss: 0.6822 - val_accuracy: 0.7369\n",
      "Epoch 5/5\n",
      "1186/1186 [==============================] - 704s 594ms/step - loss: 0.4043 - accuracy: 0.8460 - val_loss: 0.6914 - val_accuracy: 0.7419\n",
      "330/330 [==============================] - 28s 80ms/step\n",
      "\n",
      "LSTM Predictions:\n",
      " [[4.82181029e-04 1.57473347e-04 1.29887706e-03 ... 1.05253508e-04\n",
      "  1.61512871e-04 3.47547466e-04]\n",
      " [2.09757229e-04 2.39789821e-04 9.92298126e-04 ... 3.83309525e-04\n",
      "  8.61486697e-05 4.35040973e-04]\n",
      " [1.20682886e-03 9.96161580e-01 1.86011381e-03 ... 4.57796152e-04\n",
      "  2.16886416e-04 4.64421064e-05]\n",
      " ...\n",
      " [7.30681495e-05 2.18324582e-04 8.84424210e-01 ... 6.76309646e-05\n",
      "  4.35286274e-05 1.15138784e-01]\n",
      " [8.52357130e-04 3.23792687e-03 8.58530045e-01 ... 8.50513112e-04\n",
      "  2.35125865e-03 1.31450042e-01]\n",
      " [3.89861455e-03 2.94903014e-02 8.68626013e-02 ... 8.35646331e-01\n",
      "  2.99037900e-03 4.04080115e-02]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your dataframe with a 'cleaned_statement' and 'status' column\n",
    "\n",
    "# Preprocessing\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['cleaned_statement'])\n",
    "X = tokenizer.texts_to_sequences(df['cleaned_statement'])\n",
    "X = pad_sequences(X, maxlen=100)\n",
    "\n",
    "# Encode the labels\n",
    "num_classes = len(df['status'].unique())\n",
    "y = pd.get_dummies(df['status']).values\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build LSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(num_classes, activation='softmax')  # Updated to match the number of classes\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict and Evaluate\n",
    "predictions = model.predict(X_test)\n",
    "print(\"\\nLSTM Predictions:\\n\", predictions)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7908957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
